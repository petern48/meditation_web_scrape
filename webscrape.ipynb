{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install youtube-transcript-api\n",
    "# !pip install selenium\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi  # pip install youtube-transcript-api\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_LINKS = 'guided-links.txt'\n",
    "SCRIPTS_DIR = 'transcripts'\n",
    "MED_TYPES = ['focused', 'body-scan', 'visualization', 'reflection', 'movement']\n",
    "INSIGHT_DATA_FILE = 'insight-transcripts-data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about using Selenium\n",
    "\n",
    "Do the following if driver not installed in path or the usual command does not work.\n",
    "Uncomment the following two import lines in the next cell and run them\n",
    "\n",
    "Replace `driver = webdriver.Chrome()` with the following line\n",
    "`driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webdriver-manager  # alternatively install using the command line\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscrape Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_LINKS_FILE = 'yt-links.csv'\n",
    "YOUTUBE_PLAYLISTS_LINKS_FILE = 'yt-playlists.csv'\n",
    "YOUTUBE_DONE_PLAYLISTS = 'yt-playlists-done.csv'\n",
    "YOUTUBE_DATA_FILE = 'yt-transcripts-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_to_bottom(driver, times_to_scroll=None):\n",
    "    \"\"\"Scroll to the bottom of page until at very bottom of page (scroll position is equal to the scroll height)\n",
    "    Input a times_to_scroll argument to limit the number of times the page is scrolled\"\"\"\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollTop\")\n",
    "    \n",
    "    if times_to_scroll:\n",
    "        times_scrolled = 0\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "       \n",
    "        # current_scroll_position = driver.execute_script(\"return document.documentElement.scrollTop\")\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollTop\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        if times_to_scroll:\n",
    "            times_scrolled += 1\n",
    "            if times_scrolled >= times_to_scroll:\n",
    "                print(f\"Scrolled {times_scrolled} times\")\n",
    "                break\n",
    "\n",
    "        # Use to check if at bottom of page\n",
    "        if last_height == new_height:\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_to_scroll_page = 3\n",
    "\n",
    "def search_for_yt_playlists(driver, search_med_type):\n",
    "    # search only for playlists\n",
    "    url = f\"https://www.youtube.com/results?search_query={search_med_type.replace(' ', '+')}+meditation+playlists&sp=EgIQAw%253D%253D\"\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    scroll_to_bottom(driver, times_to_scroll_page)\n",
    "\n",
    "    with open(YOUTUBE_PLAYLISTS_LINKS_FILE, 'a', newline='', encoding=\"utf-8\") as csvf:\n",
    "        writer = csv.writer(csvf)\n",
    "\n",
    "        # Add headers if file is empty\n",
    "        if os.path.getsize(YOUTUBE_PLAYLISTS_LINKS_FILE) == 0:\n",
    "            writer.writerow(['Meditation Type', 'Playlist Link'])\n",
    "\n",
    "        playlist_box_list = driver.find_elements(By.TAG_NAME, 'ytd-playlist-renderer')\n",
    "        for playlist_box in playlist_box_list:\n",
    "            title = playlist_box.find_element(By.ID, 'video-title').text.lower()\n",
    "\n",
    "            temp_med_type = search_med_type.replace('-', ' ').replace('ed', '').replace('ization', '').replace('ion', '')\n",
    "            # Skip playlists that have music or ones that dont have meditation or the meditation type\n",
    "            if 'music' in title or 'song' in title:\n",
    "                print(f\"'{title}' playlist skipped bc it has 'music' or 'song'\")\n",
    "                continue\n",
    "            if temp_med_type not in title and 'meditat' not in title and 'mindful' not in title and 'relax' not in title:\n",
    "                print(f\"'{title}' playlist skipped bc it doesn't have '{temp_med_type}' or 'meditat' or 'mindful' or 'relax' in it\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            url = playlist_box.find_element(\n",
    "                By.ID, 'view-more').find_element(\n",
    "                    By.TAG_NAME, 'a').get_attribute('href')\n",
    "\n",
    "            writer.writerow([search_med_type, url, title])\n",
    "    print(f\"Done writing {search_med_type} playlists to {YOUTUBE_PLAYLISTS_LINKS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_links_from_playlist(driver, playlist_url, med_type):\n",
    "\n",
    "    driver.get(playlist_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Scroll to bottom of page to reveal all the links\n",
    "    scroll_to_bottom(driver)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    playlist = wait.until(\n",
    "        EC.presence_of_element_located(\n",
    "            (By.TAG_NAME, 'ytd-playlist-video-list-renderer')\n",
    "        )\n",
    "    )\n",
    "    vid_boxes = playlist.find_elements(By.TAG_NAME, 'ytd-playlist-video-renderer')\n",
    "\n",
    "    with open(YOUTUBE_LINKS_FILE, 'a', newline='') as csvf:\n",
    "        writer = csv.writer(csvf)\n",
    "        for box in vid_boxes:\n",
    "            link = box.find_element(By.TAG_NAME, 'a')\n",
    "            url = link.get_attribute('href')\n",
    "            writer.writerow([med_type, url])\n",
    "    print(f'Wrote {str(len(vid_boxes))} more links into {YOUTUBE_LINKS_FILE}')\n",
    "\n",
    "    return YOUTUBE_LINKS_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_youtube_transcript(youtube_url, med_type):\n",
    "    sep = '&'\n",
    "    # Strip the url in before the id and any extra q = pairs that come after the '&\n",
    "    youtube_id = youtube_url.lstrip('https://www.youtube.com/watch?v=').split(sep, 1)[0]\n",
    "\n",
    "    # Returns a list of dicts\n",
    "    script = YouTubeTranscriptApi.get_transcript(youtube_id, languages=['en'])\n",
    "\n",
    "    # new_file = os.path.join(YOUTUBE_SCRIPTS_DIR, f'ytscript-{youtube_id}.txt')\n",
    "\n",
    "    script_string = ''\n",
    "    for yt_dict in script:\n",
    "        script_string += yt_dict['text'] + ' '\n",
    "\n",
    "    # Remove bracketed phrases  e.g [Music]\n",
    "    fixed_script = re.sub(r'\\[(.*?)\\]', '', script_string)\n",
    "    # Remove parentheses e.g (Music)\n",
    "    fixed_script = re.sub(r'\\((.*?)\\)', ' ', fixed_script)\n",
    "    # Remove the newlines from the script\n",
    "    fixed_script = re.sub(r'\\n', ' ', fixed_script)\n",
    "\n",
    "    # Write to data file\n",
    "    with open(YOUTUBE_DATA_FILE, 'a', newline='', encoding='utf8') as csvf:\n",
    "        writer = csv.writer(csvf)\n",
    "        writer.writerow([med_type, youtube_url, fixed_script])\n",
    "    print(f'Written line for {youtube_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE\n",
    "# Get list of links to playslists for each type of meditation and store in a file\n",
    "# Skip playlists if their playlist titles don't seem right\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "for med_type in MED_TYPES:\n",
    "    search_med_type = med_type\n",
    "    search_for_yt_playlists(driver, search_med_type)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE\n",
    "# Get links to each of the videos in each of the playlists\n",
    "# Reads the links into YOUTUBE_LINKS_FILE\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "with open(YOUTUBE_PLAYLISTS_LINKS_FILE, 'r', encoding='utf8') as csvf:\n",
    "    reader = csv.reader(csvf)\n",
    "    next(reader)  # Skip the header\n",
    "    for row in reader:\n",
    "        meditation_type = row[0]\n",
    "        link = row[1]\n",
    "        print('playlist link: ', link)\n",
    "        get_youtube_links_from_playlist(driver, link, meditation_type)\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE\n",
    "# Use youtube api to read the transcripts into the data file\n",
    "\n",
    "failed_writes = 0\n",
    "# Read urls from file into a list\n",
    "with open(YOUTUBE_LINKS_FILE, 'r') as csvf:\n",
    "    reader = csv.reader(csvf)\n",
    "    med_types = []\n",
    "    yt_vid_urls = []\n",
    "    for row in reader:\n",
    "        med_types.append(row[0])\n",
    "        yt_vid_urls.append(row[1].rstrip())\n",
    "\n",
    "# Add header if file is empty\n",
    "if os.path.getsize(YOUTUBE_PLAYLISTS_LINKS_FILE) == 0:\n",
    "    with open(YOUTUBE_DATA_FILE, 'a') as csvf:\n",
    "        writer = csv.writer(csvf)\n",
    "        writer.writerow(['Meditation_Type', 'URL', 'Script', ])\n",
    "\n",
    "assert(len(yt_vid_urls) == len(med_types))\n",
    "\n",
    "# For each url, read into the data file\n",
    "for i in range(len(yt_vid_urls)):\n",
    "    try:\n",
    "        read_youtube_transcript(yt_vid_urls[i], med_types[i])\n",
    "    except:\n",
    "        failed_writes += 1  # occurs if subtitles are turned off for video\n",
    "\n",
    "\n",
    "print(f\"Done!\")\n",
    "print(f'Failed writes: {failed_writes}')\n",
    "print(f'Successful writes: {len(yt_vid_urls) - failed_writes} new transcripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning Code has been moved to `data_clean.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created new file `med-transcript-dataset.csv` with the insight timer data followed by the youtube data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add special tokens to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_FILE = 'med-transcript-dataset.csv'\n",
    "TOKENIZED_DATA_FILE = 'tokenized-dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written tokenized data file to tokenized-dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv(INPUT_DATA_FILE, encoding=\"utf8\")  # encoding=\"ISO-8859-1\"  Original\n",
    "# df = df.dropna()  # DO NOT dropna() because insight timer rows have nan urls\n",
    "# Empty file\n",
    "with open(TOKENIZED_DATA_FILE, 'w') as f:\n",
    "    f.truncate(0)\n",
    "\n",
    "with open(TOKENIZED_DATA_FILE, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Meditation_Type','URL','Script'])\n",
    "    for idx, item in df.iterrows():\n",
    "        script = item['Script']\n",
    "        url = item['URL']\n",
    "        med_type = item['Meditation_Type']\n",
    "\n",
    "        # ADD SPECIAL TOKEN indicating the meditation type\n",
    "        if type(med_type)==str:\n",
    "            special_token = f'[{med_type} MEDITATION]'.upper()\n",
    "        # If nan values (type float), then don't add token\n",
    "        else:\n",
    "            special_token = \"\"\n",
    "\n",
    "        script = f'{special_token} {script}'\n",
    "\n",
    "        writer.writerow([med_type, url, script])\n",
    "\n",
    "print(f\"Written tokenized data file to {TOKENIZED_DATA_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscrape Insighttimer Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_guided_links(driver):\n",
    "    time.sleep(3)\n",
    "    grid = driver.find_element(By.CSS_SELECTOR, '.MuiGrid-root.MuiGrid-container.MuiGrid-spacing-xs-3')\n",
    "    print(grid)\n",
    "\n",
    "    print('Starting to Scroll Down')\n",
    "    # Scroll to the bottom of page to load more links\n",
    "    for _ in range(400):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.5)\n",
    "    print('Done Scrolling Down')\n",
    "\n",
    "    links = grid.find_elements(By.TAG_NAME, 'a')\n",
    "    print(\"Num Links\", len(links))\n",
    "\n",
    "    with open(FILE_NAME_LINKS, \"w\") as f:  # Empty contents of file\n",
    "        f.truncate(0)\n",
    "\n",
    "    with open(FILE_NAME_LINKS, 'a') as f:\n",
    "\n",
    "        for link_ele in links:\n",
    "            guided_or_music = link_ele.find_element(By.CSS_SELECTOR, '.chakra-text.css-gxmra2').text\n",
    "            if 'GUIDED' in guided_or_music:\n",
    "                # Save the link\n",
    "                link = link_ele.get_attribute('href')\n",
    "                f.write(link + '\\n')\n",
    "            # else skip the link if it lists 'MUSIC'\n",
    "    \n",
    "    return FILE_NAME_LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_has_transcript(driver, url):\n",
    "\n",
    "    try:\n",
    "        transcript = driver.find_element(By.XPATH, \"//*[text()='Transcript']\")\n",
    "        if transcript.text == 'Transcript':\n",
    "            print('Transcript Found')\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transcript_insighttimer(driver, url):\n",
    "    \"\"\"Reads the transcript on the page into a .txt file\"\"\"\n",
    "    div = driver.find_element(By.CLASS_NAME, 'css-14kzvyt')\n",
    "    more_button = driver.find_element(By.CSS_SELECTOR, '.chakra-button.css-ryu1zs')\n",
    "\n",
    "    # scroll button into view and click\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({ behavior: 'smooth', block: 'nearest', inline: 'start' });\", div)\n",
    "    time.sleep(2)\n",
    "    more_button.click()\n",
    "    \n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    body = wait.until(\n",
    "        EC.presence_of_element_located(\n",
    "            (By.CLASS_NAME, 'MuiCollapse-wrapperInner')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    line_text = driver.find_elements(By.CLASS_NAME, 'css-dbagas')\n",
    "    \n",
    "    id = url.lstrip('https://insighttimer.com/guided-meditations/').rstrip()\n",
    "    print('id', id)\n",
    "    new_file = os.path.join(SCRIPTS_DIR, f'script-{id}.txt')\n",
    "\n",
    "    # Write text to a .txt file\n",
    "    with open(new_file, 'a') as f:\n",
    "        f.write(url + '\\n')  # First line has url\n",
    "\n",
    "        for line in line_text:\n",
    "            f.write(line.text + '\\n')\n",
    "    print(f'Written .txt for {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcripts_from_links(driver):\n",
    "\n",
    "    with open(FILE_NAME_LINKS, 'r') as f:\n",
    "        guided_urls = f.readlines()\n",
    "    \n",
    "    for url in guided_urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "        if page_has_transcript(driver, url):\n",
    "            # Extract the Script\n",
    "            read_transcript_insighttimer(driver, url)\n",
    "\n",
    "    print('DONE WITH ALL LINKS')\n",
    "\n",
    "    time.sleep(10) # Let the user actually see something!\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(transcripts_dir):\n",
    "    \"\"\"Removes the extra newlines from all the files in the given directory\"\"\"\n",
    "\n",
    "    for file_name in os.listdir(transcripts_dir):\n",
    "        # Remove the extra new lines in the file\n",
    "\n",
    "        with open(os.path.join(transcripts_dir, file_name), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        with open(os.path.join(transcripts_dir, file_name), 'w') as f:\n",
    "            for line in lines:\n",
    "                if line != '\\n' and line != ' \\n':\n",
    "                    f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(csv_file, scripts_dir):\n",
    "    \"\"\"Create csv file given scripts_dir\"\"\"\n",
    "    with open(csv_file, 'w', newline='') as csvf:\n",
    "        writer = csv.writer(csvf)\n",
    "\n",
    "        # Column Names\n",
    "        writer.writerow(['Meditation_Type', 'Script'])\n",
    "        for file_name in os.listdir(scripts_dir):\n",
    "            with open(os.path.join(scripts_dir, file_name), 'r') as f:\n",
    "\n",
    "                first_line = f.readline()\n",
    "                if not first_line.startswith('http'):\n",
    "                    print(f'file {file_name} does not start with a http link')\n",
    "                    sys.exit()\n",
    "\n",
    "                key = ''\n",
    "                # Add the type of meditation if listed\n",
    "                for type in MED_TYPES:\n",
    "                    if file_name.startswith(type):\n",
    "                        key = f'{type} '\n",
    "                        break\n",
    "\n",
    "                # key += 'meditation'\n",
    "                print(key)\n",
    "\n",
    "                text = f.read()\n",
    "\n",
    "                writer.writerow([key, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://insighttimer.com/guided-meditations'\n",
    "driver = webdriver.Chrome()\n",
    "# Use this line instead if driver not installed in path\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.get(URL)\n",
    "time.sleep(2)\n",
    "\n",
    "# Scroll through and save all 10,000 links on the page\n",
    "save_guided_links(driver)\n",
    "\n",
    "# Using the list of links, go through and check for and save thei transcripts\n",
    "get_transcripts_from_links(driver)\n",
    "\n",
    "remove_newlines(SCRIPTS_DIR)\n",
    "\n",
    "create_csv(INSIGHT_DATA_FILE, SCRIPTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
